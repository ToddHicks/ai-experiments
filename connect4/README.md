The standard postgres server and the standardized model have some key difference. 
The postgres server ended up being overly optimistic, after 2000 play throughs it could play pretty solidly, but if you started in the position second from the right, you could always win by going straight along the bottom.
The reason for this was because rewards were given per turn taken, but since that resulted in a score above 0, that became the best option.
The new model is modified such that the penalty is smaller depending on turns taken, but always below 0. The result is the model is slower 
to learn, because it still takes a number of losses before a choice becomes below the reward for taking an extra turn. I've played with adjusting to bad decisions quicker, but this will also result in good decisions being downgraded faster. On top of this. If a player is intending on just stacking for pieces, the AI has 40+ possible combinations that will completely stay out of the way, and only 3 that will actually block it, and of those 3 only 2 will guarantee an extra turn. Going straight up is the hardest part of the model to learn, once it gets past that it learns fairly well because it is possible for other starting locations to than overlap. I still suspect it'll take 15000 or more plays before the AI could consistenly beat a 13 year old.

The UI does have some bugs to sort out yet, such as if a game grows stale, if a player tries to return to it we need to print an error and give the new game button. I also need to handle screen size more dynamically. My current goal is the learning side though, so this is a lower priority.
